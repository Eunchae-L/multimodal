{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ppKQP4QNjM-q",
        "RgZpPzdMYxxi",
        "ApqC0Q0_Y30R",
        "kbNieq2kY8OV",
        "B_w8r2bNY-ZY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 멀티모달 세션 1회"
      ],
      "metadata": {
        "id": "w03_QNmFNIzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM에 눈달기(Vision)"
      ],
      "metadata": {
        "id": "ppKQP4QNjM-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> LLM은 코어 뇌임\n",
        ">"
      ],
      "metadata": {
        "id": "h5uQn_3XYsmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Computer Vision과 Image Generation의 차이**"
      ],
      "metadata": {
        "id": "RgZpPzdMYxxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Computer Vision은 눈과 시각세포 → 짧게 Vision이라고 한다. → 이미지를 이해하는 능력\n",
        "- Image Generation은 손과 그림 그리기 → 그림을 그리는 능력, Creative의 영역"
      ],
      "metadata": {
        "id": "wQsavNxvYzTY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vision 모델의 의미**"
      ],
      "metadata": {
        "id": "ApqC0Q0_Y30R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 픽셀조합은 Semantic 의미가 없지만, 여기에 Semantic 의미를 부여하는건 우리의 눈과 시신경세포\n",
        "- 이 우주에서 픽셀조합에 Semantic 의미를 부여할 수 있는건 우리의 눈과 시신경세포가 유일했음\n",
        "- 그러나 비전 모델을 통해서 그 존재가 생겨난 것!\n",
        "- 인간 대신에 픽셀 뭉치에서 언어적 의미를 추출할 수 있게 된 것"
      ],
      "metadata": {
        "id": "wTL3A2pcY7DB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **비전으로 할 수 있는 것들**"
      ],
      "metadata": {
        "id": "kbNieq2kY8OV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 비정형 이미지 데이터에서 다양한 형태의 데이터를 추출할 수 있음\n",
        "    - 비정형 이미지 → 비정형 텍스트\n",
        "    - 비정형 이미지 → 정형 텍스트\n",
        "- 가장 먼저 발전된 분야가 의료 비전 분야였음\n",
        "    - 의료영상에서 질병 진단하기\n",
        "- 아이패드 굿노트의 필기는 추출하면 픽셀로 이루어진 이미지 데이터\n",
        "    - 필기의 내용은 단순한 픽셀조합이지만, 이를 비전을 통해서 비정형 텍스트나\n",
        "    - 정형 데이터 (노션, 지식그래프 등)의 형태로 저장 가능\n",
        "    - 이렇게 텍스트 형태로 저장된 데이터는 LLM이 처리할 수 있기 때문에 대화가 가능해짐\n",
        "- 그림 그려서 웹사이트 코드 뽑기\n",
        "    - tldraw make real 보여주기\n",
        "- 혼자서 웹브라우저 조작하기\n",
        "    - 실시간 영상을 프레임으로 쪼개서 실시간으로 웹브라우저 서핑을 하는 모델"
      ],
      "metadata": {
        "id": "VtrwCEQIY9o8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **비전 실습하기**"
      ],
      "metadata": {
        "id": "B_w8r2bNY-ZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "ZIB997g6jO-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a008310-828c-4323-a9aa-676e40355bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.25.0-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "온라인상의 url 이미지 분석해보기"
      ],
      "metadata": {
        "id": "4wMfaJXSKe3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "API_KEY = 'your_api_key'\n",
        "client = OpenAI(api_key = API_KEY)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},# prompting\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
        "          },\n",
        "        },\n",
        "      ],\n",
        "    }\n",
        "  ],\n",
        "  max_tokens=300,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "v5psxl_HjPUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "필기 내용 물어보기!"
      ],
      "metadata": {
        "id": "IaDu67HdjjUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "local에 있는 image를 업로드하여 사용하기 위해서는 base64 encoding을 거쳐야 한다!(호환성문제)"
      ],
      "metadata": {
        "id": "ugWJ6PfKjxoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import requests\n",
        "\n",
        "# OpenAI API Key\n",
        "api_key = \"your API key\"\n",
        "\n",
        "\n",
        "# Function to encode the image\n",
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "# Path to your image\n",
        "image_path = \"/content/수업필기예시.jpg\"\n",
        "\n",
        "# Getting the base64 string\n",
        "base64_image = encode_image(image_path)\n",
        "\n",
        "headers = {\n",
        "  \"Content-Type\": \"application/json\",\n",
        "  \"Authorization\": f\"Bearer {api_key}\"\n",
        "}\n",
        "\n",
        "payload = {\n",
        "  \"model\": \"gpt-4-turbo\",\n",
        "  \"messages\": [\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"text\",\n",
        "          \"text\": \"What’s in this image?\"\n",
        "        },#image_url type을 여러장 넣으면 multi image도 가능하다!\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "          }\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ],\n",
        "  \"max_tokens\": 300\n",
        "}\n",
        "\n",
        "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "\n",
        "print(response.json()['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "id": "PeYo1hxBjPSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113a91f2-8ffd-4dfa-9df0-690358c0ee01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image is a slide presentation that appears to discuss the topic of solving systems of equations, specifically focusing on simultaneous non-linear equations and finding their common roots. Here is a breakdown of the content on the slide:\n",
            "\n",
            "1. **Title**: \"System of Equations\"\n",
            "  \n",
            "2. **Content**:\n",
            "   - **Main Topic**: Common roots of a set of simultaneous non-linear equations\n",
            "   - **Subsection - How to solve system of equations**:\n",
            "     - It lists a general form of system equations \\[ f_1(x_1, x_2, ..., x_n) = 0, f_2(x_1, x_2, ..., x_n) = 0, ..., f_n(x_1, x_2, ..., x_n) = 0 \\].\n",
            "   - **Subsection - Newton-Raphson approach**:\n",
            "     - Examples are given as \\[ u(x, y) \\] and \\[ v(x, y) \\] equations.\n",
            "     - Mathematical expressions illustrating the update or the iterative scheme to find a solution using partial derivatives.\n",
            "\n",
            "The slide uses mathematical notations and provides formulae typical in discussions of numerical methods such as the Newton-Raphson method (a technique widely used for finding successively better approximations to the roots, or zeros, of a real-valued function). The notations imply partial differentiation, adjusting variables \\(x\\) and \\(y\\) to gradually approach the solution of the equations set to zero.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM에 귀달기(Whisper api)"
      ],
      "metadata": {
        "id": "wHRMgaz_kGPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- audio를 통해 들어오는 내용 text로 transcription!\n",
        "\n",
        "- audio를 english로 translate"
      ],
      "metadata": {
        "id": "iy5ghqARuhBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 민족의 아리아 transcription해보기\n",
        "from openai import OpenAI\n",
        "API_KEY = \"your_api_key\"\n",
        "client = OpenAI(api_key = API_KEY)\n",
        "\n",
        "audio_file= open(\"/content/민족의 아리아.mp3\", \"rb\")\n",
        "transcription = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=audio_file,\n",
        "  prompt = \"고대,지축,포효,조국,고동,자유\"\n",
        ")\n",
        "print(transcription)"
      ],
      "metadata": {
        "id": "g-cXc-igjPPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4492498-5e8e-4076-f613-b8724a2f237a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription(text='트위터 interface 가오리  열차의 날아가는 정의 손꼽히듯 진리 민족의 힘으로 부대 애니멀 사운드 발사 자 치축을 받자고 자 고요하라 군대 서풍의 영원한 곧 오는 날이라 자 치축을 받자고 자 고요하라 군대 서풍의 영원한 곧 오는 날이라 자 치축을 받자고 자 고요하라 군대 서풍의 영원한 곧 오는 날이라 자 치축을 받자고 자 고요하라 군대 서풍의 영원한 곧 오는 날이라 서풍의 영원한 곧 오는 날이라 자 치축을 받자고 자 고요하라 군대 서풍의 영원한 곧 오는 날이라 서풍의 영원한 곧 오는 날이라')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "발음이 뭉개지거나 spelling이 어려운 단어들은 prompting을 통해 보정하거나\n",
        "\n",
        "gpt-4를 사용하여 후보정작업을 할 수 있다"
      ],
      "metadata": {
        "id": "AJ-V_42AwM8F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM에 입달기(texttospeech)"
      ],
      "metadata": {
        "id": "YmBCj89lkQle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 다양한 언어로 말하기\n",
        "- 블로그 글 읽어주기등등으로 활용가능!"
      ],
      "metadata": {
        "id": "LHzb-NMPk3kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###OpenAI TTS"
      ],
      "metadata": {
        "id": "J9zokkdDvi5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "API_KEY = 'your_api_key'\n",
        "client = OpenAI(api_key = API_KEY)\n",
        "\n",
        "\n",
        "response = client.audio.speech.create(\n",
        "    model=\"tts-1\",\n",
        "    voice=\"onyx\",\n",
        "    input=\"뭐, 갈 때 가더라도 담배 한 대 정도는 괜찮잖아? 응?\",\n",
        ")\n",
        "\n",
        "response.stream_to_file(\"output.mp3\") # 파일에 생성됨"
      ],
      "metadata": {
        "id": "HaHQGooPv0Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ElevenLabs TTS"
      ],
      "metadata": {
        "id": "spWLKSIQvhGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ElevenLabs api 독스: https://elevenlabs.io/docs/introduction"
      ],
      "metadata": {
        "id": "MZ_TprcR_VsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ElevenLabs api key: https://elevenlabs.io/app/voice-lab"
      ],
      "metadata": {
        "id": "_usyaTWZBAeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "voice 추가: https://elevenlabs.io/app/voice-lab"
      ],
      "metadata": {
        "id": "U7H5nUusABlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "CHUNK_SIZE = 1024\n",
        "url = \"https://api.elevenlabs.io/v1/text-to-speech/<voice_id>\"\n",
        "\n",
        "headers = {\n",
        "  \"Accept\": \"audio/mpeg\",\n",
        "  \"Content-Type\": \"application/json\",\n",
        "  \"xi-api-key\": \"<api-key>\"\n",
        "}\n",
        "\n",
        "data = {\n",
        "  \"text\": \"\"\"타오르는 자유. 나아가는 정의. 솟구치는 진리! 민족의 힘으로!\n",
        "자 지축을 박차고, 자 포효하라 그대. 조국의 영원한 고동이 되리라. 자 지축을 박차고, 자 포효하라 그대. 조국의 영원한 고동이 되리라.\"\"\",\n",
        "  \"model_id\": \"eleven_monolingual_v1\",\n",
        "  \"voice_settings\": {\n",
        "    \"stability\": 0.5,\n",
        "    \"similarity_boost\": 0.5\n",
        "  }\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=data, headers=headers)\n",
        "with open('output.mp3', 'wb') as f:\n",
        "    for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
        "        if chunk:\n",
        "            f.write(chunk)"
      ],
      "metadata": {
        "id": "5OtIb684vhf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LLM에 얼굴 만들기"
      ],
      "metadata": {
        "id": "U2euKCrjTEFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "D-iD api 독스: https://docs.d-id.com/reference/overview"
      ],
      "metadata": {
        "id": "RlzW2AOr-xof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "D-iD api key: https://studio.d-id.com/account-settings"
      ],
      "metadata": {
        "id": "2adiTm-6BW-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ElevenLabs에서 목소리 가져오기:\n",
        "\n",
        "https://api.elevenlabs.io/v1/voices"
      ],
      "metadata": {
        "id": "04kKjakt-0dH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "url = \"https://api.d-id.com/talks\"\n",
        "\n",
        "headers = {\n",
        "    \"accept\": \"application/json\",\n",
        "    \"content-type\": \"application/json\",\n",
        "    \"Authorization\": \"Basic <api-key>\"\n",
        "}\n",
        "\n",
        "payload = {\n",
        "    \"script\": {\n",
        "        \"type\": \"text\",\n",
        "        \"subtitles\": False,\n",
        "        \"provider\": {\n",
        "            \"type\": \"elevenlabs\",\n",
        "            \"voice_id\": \"<voice_id>\",\n",
        "            \"voice_config\":{\n",
        "                    \"stability\":0.5,\n",
        "                    \"similarity_boost\":0.5\n",
        "            }\n",
        "        },\n",
        "        \"input\":  \"\"\"Hi. KAIROS. Nice to meet you guys.\"\"\",\n",
        "        \"ssml\": True\n",
        "    },\n",
        "    \"source_url\": \"https://img.freepik.com/free-photo/smiling-asian-young-woman-face-portrait_53876-145636.jpg\",\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=payload, headers=headers)\n",
        "print(response.text)\n",
        "response_data = response.json()\n",
        "talk_id = response_data.get(\"id\")\n",
        "\n",
        "while True:\n",
        "    # 비디오 상태 확인 요청\n",
        "    status_url = f\"https://api.d-id.com/talks/{talk_id}\"\n",
        "    status_response = requests.get(status_url, headers=headers)\n",
        "\n",
        "\n",
        "    status_data = status_response.json()\n",
        "    status = status_data.get(\"status\")\n",
        "\n",
        "    if status == \"done\":\n",
        "        result_url = status_data.get(\"result_url\")\n",
        "\n",
        "        if result_url:\n",
        "            print(\"Video URL:\", result_url)\n",
        "\n",
        "            # 비디오 다운로드 요청\n",
        "            video_response = requests.get(result_url, stream=True)\n",
        "\n",
        "            if video_response.status_code == 200:\n",
        "                with open(\"output.mp4\", \"wb\") as f:\n",
        "                    for chunk in video_response.iter_content(chunk_size=1024):\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "                print(\"Video saved as output.mp4\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Error downloading video:\", video_response.text)\n",
        "                break\n",
        "\n",
        "\n",
        "    elif status in [\"created\", \"started\"]:\n",
        "        print(\"Status:\", status)\n",
        "        time.sleep(10)  # 10초 후에 상태 재확인\n",
        "    else:\n",
        "        print(\"Unexpected status:\", status_response.text)\n",
        "        break"
      ],
      "metadata": {
        "id": "hWvcK6jNjPCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LLM에 시간을 이해하는 눈 달기"
      ],
      "metadata": {
        "id": "LgAYRYvDUxi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TwelveLabs api 독스: https://docs.twelvelabs.io/reference/generate-text-representation"
      ],
      "metadata": {
        "id": "T8Pdnz8zzjmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TwelveLabs api key: https://dashboard.twelvelabs.io/home"
      ],
      "metadata": {
        "id": "aQ6hmDwsBwVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "원하는 영상을 직접 업로드\n",
        "\n",
        "https://playground.twelvelabs.io/indexes"
      ],
      "metadata": {
        "id": "LFOy8cKjztwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://api.twelvelabs.io/v1.2/generate\"\n",
        "\n",
        "headers = {\n",
        "    \"x-api-key\": \"<api_key>\",\n",
        "    \"accept\": \"application/json\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"video_id\": \"<video_id>\",\n",
        "    \"prompt\": \"2분에 무슨 장면이 나와?\",\n",
        "    \"temperature\": 0.7\n",
        "}\n",
        "\n",
        "\n",
        "response = requests.post(url, json=data, headers=headers)\n",
        "\n",
        "print(response.json().get(\"data\"))"
      ],
      "metadata": {
        "id": "q0W7glHUUzp8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}